# src/core/model_manager.py
"""
model_manager.py - Verwaltet die Modelle für Mindestentinel

Diese Datei implementiert die Verwaltung von KI-Modellen für das System.
Es ermöglicht das Laden, Speichern und Verwalten von Modellen.
"""

import logging
import os
import json
import time
import threading
from typing import Dict, Any, Optional, List
try:

    from transformers import AutoModelForCausalLM, AutoTokenizer
except Exception:
    from src.core._stubs import AutoModelForCausalLM, AutoTokenizer

except Exception:
    AutoModelForCausalLM = None
AutoTokenizer = None

logger = logging.getLogger("mindestentinel.model_manager")

class ModelManager:
    """
    Verwaltet die KI-Modelle für das System.
    
    Lädt, speichert und verwaltet Modelle und ihre Metadaten.
    """
    
    def __init__(self, models_dir: str = "data/models"):
        """
        Initialisiert den ModelManager.
        
        Args:
            models_dir: Pfad zum Modell-Verzeichnis
        """
        self.models_dir = models_dir
        self.models = {}
        self.model_metadata = {}
        self.model_registry = {}
        self.monitoring = False
        self.monitor_thread = None
        
        # Erstelle Modell-Verzeichnis, falls nicht vorhanden
        os.makedirs(self.models_dir, exist_ok=True)
        
        # Lade Modelle aus dem Verzeichnis
        self.load_models()
        
        # Lade die Modell-Registry
        self.load_model_registry()
        
        # Starte die Modellverzeichnis-Überwachung
        self.monitor_model_directory()
        
        logger.info(f"ModelManager initialisiert mit {len(self.models)} Modellen aus {self.models_dir}.")
    
    def _is_valid_model_directory(self, model_path: str) -> bool:
        """
        Prüft, ob ein Verzeichnis ein gültiges Modell enthält.
        
        Args:
            model_path: Pfad zum zu prüfenden Verzeichnis
            
        Returns:
            bool: True, wenn es ein gültiges Modell ist, sonst False
        """
        # Prüfe, ob die erforderlichen Dateien existieren
        required_files = [
            "config.json",
            ("pytorch_model.bin", "model.safetensors", "tf_model.h5", "model.ckpt.index", "flax_model.msgpack")
        ]
        
        # Prüfe config.json
        if not os.path.exists(os.path.join(model_path, "config.json")):
            return False
            
        # Prüfe mindestens eine der Modell-Dateien
        model_files_exist = False
        for file_option in required_files[1]:
            if os.path.exists(os.path.join(model_path, file_option)):
                model_files_exist = True
                break
                
        if not model_files_exist:
            return False
            
        return True
    
    def load_models(self):
        """Lädt alle Modelle aus dem Modell-Verzeichnis."""
        try:
            # Hole alle Unterordner im Modell-Verzeichnis
            model_names = []
            for d in os.listdir(self.models_dir):
                d_path = os.path.join(self.models_dir, d)
                if os.path.isdir(d_path) and self._is_valid_model_directory(d_path):
                    model_names.append(d)
            
            for model_name in model_names:
                try:
                    # Versuche, das Modell zu laden
                    model_path = os.path.join(self.models_dir, model_name)
                    model = None
_model_cls = globals().get('AutoModelForCausalLM') or getattr(globals().get('transformers', None) or __import__('types').SimpleNamespace(), 'AutoModelForCausalLM', None)
if callable(_model_cls):
    try:
        model = _model_cls.from_pretrained(model_path)
    except Exception as e:
        LOG.warning("Failed to load model for %s: %s", model_path, e)
        model = None
else:
    LOG.warning("AutoModelForCausalLM not available; skipping model load for %s", model_path)
    model = None
                    tokenizer = None
_tokenizer_cls = globals().get('AutoTokenizer') or getattr(globals().get('transformers', None) or __import__('types').SimpleNamespace(), 'AutoTokenizer', None)
if callable(_tokenizer_cls):
    try:
        tokenizer = _tokenizer_cls.from_pretrained(model_path)
    except Exception as e:
        LOG.warning("Failed to load tokenizer for %s: %s", model_path, e)
        tokenizer = None
else:
    LOG.warning("AutoTokenizer not available; skipping tokenizer load for %s", model_path)
    tokenizer = None
                    
                    # Speichere das Modell
                    self.models[model_name] = {
                        "model": model,
                        "tokenizer": tokenizer
                    }
                    
                    # Lade Metadaten, falls vorhanden
                    metadata_path = os.path.join(model_path, "metadata.json")
                    if os.path.exists(metadata_path):
                        with open(metadata_path, 'r') as f:
                            self.model_metadata[model_name] = json.load(f)
                    else:
                        # Erstelle Standard-Metadaten
                        self.model_metadata[model_name] = {
                            "name": model_name,
                            "created_at": time.time(),
                            "last_loaded": time.time(),
                            "usage_count": 0,
                            "success_rate": 0.0,
                            "resource_usage": {
                                "cpu": 0.0,
                                "memory": 0.0,
                                "gpu": 0.0
                            },
                            "version": "1.0",
                            "description": f"Modell {model_name}"
                        }
                    
                    logger.info(f"Modell '{model_name}' erfolgreich geladen.")
                except Exception as e:
                    logger.error(f"Fehler beim Laden des Modells '{model_name}': {str(e)}", exc_info=True)
        
        except Exception as e:
            logger.error(f"Fehler beim Laden der Modelle: {str(e)}", exc_info=True)
    
    def load_model_registry(self):
        """Lädt die Modell-Registry aus der Registry-Datei."""
        registry_path = os.path.join(self.models_dir, "model_registry.json")
        
        if os.path.exists(registry_path):
            try:
                with open(registry_path, 'r') as f:
                    self.model_registry = json.load(f)
                logger.info(f"Geladen: {len(self.model_registry)} Modelle aus model_registry.json")
            except Exception as e:
                logger.error(f"Fehler beim Laden der Modell-Registry: {str(e)}", exc_info=True)
                self.model_registry = {}
        else:
            # Erstelle eine neue Registry
            self.model_registry = {}
            self.save_model_registry()
    
    def save_model_registry(self):
        """Speichert die Modell-Registry in die Registry-Datei."""
        registry_path = os.path.join(self.models_dir, "model_registry.json")
        
        try:
            with open(registry_path, 'w') as f:
                json.dump(self.model_registry, f, indent=2)
            logger.debug("Modell-Registry gespeichert.")
        except Exception as e:
            logger.error(f"Fehler beim Speichern der Modell-Registry: {str(e)}", exc_info=True)
    
    def get_model(self, model_name: str) -> Optional[Dict[str, Any]]:
        """
        Gibt ein Modell zurück.
        
        Args:
            model_name: Der Name des Modells
            
        Returns:
            Optional[Dict[str, Any]]: Das Modell und seine Metadaten, falls gefunden, sonst None
        """
        if model_name in self.models:
            # Erhöhe den Usage-Count
            self.model_metadata[model_name]["usage_count"] += 1
            self.model_metadata[model_name]["last_loaded"] = time.time()
            
            # Aktualisiere die Registry
            if model_name in self.model_registry:
                self.model_registry[model_name]["usage_count"] = self.model_metadata[model_name]["usage_count"]
                self.model_registry[model_name]["last_loaded"] = self.model_metadata[model_name]["last_loaded"]
                self.save_model_registry()
            
            return {
                "model": self.models[model_name]["model"],
                "tokenizer": self.models[model_name]["tokenizer"],
                "metadata": self.model_metadata[model_name]
            }
        else:
            logger.warning(f"Modell '{model_name}' nicht gefunden.")
            return None
    
    def register_model(self, model_name: str, model: Any, tokenizer: Any, metadata: Optional[Dict[str, Any]] = None):
        """
        Registriert ein neues Modell.
        
        Args:
            model_name: Der Name des Modells
            model: Das Modell
            tokenizer: Der Tokenizer
            metadata: Optionale Metadaten
        """
        # Speichere das Modell
        self.models[model_name] = {
            "model": model,
            "tokenizer": tokenizer
        }
        
        # Erstelle Metadaten, falls nicht vorhanden
        if metadata is None:
            metadata = {
                "name": model_name,
                "created_at": time.time(),
                "last_loaded": time.time(),
                "usage_count": 0,
                "success_rate": 0.0,
                "resource_usage": {
                    "cpu": 0.0,
                    "memory": 0.0,
                    "gpu": 0.0
                },
                "version": "1.0",
                "description": f"Modell {model_name}"
            }
        
        # Speichere die Metadaten
        self.model_metadata[model_name] = metadata
        
        # Aktualisiere die Registry
        self.model_registry[model_name] = {
            "name": model_name,
            "created_at": metadata["created_at"],
            "usage_count": metadata["usage_count"],
            "success_rate": metadata["success_rate"],
            "version": metadata["version"],
            "path": os.path.join(self.models_dir, model_name)
        }
        self.save_model_registry()
        
        logger.info(f"Modell '{model_name}' registriert.")
    
    def unregister_model(self, model_name: str):
        """
        Entfernt ein Modell aus der Registry.
        
        Args:
            model_name: Der Name des Modells
        """
        if model_name in self.models:
            # Entferne das Modell
            del self.models[model_name]
            
            # Entferne die Metadaten
            if model_name in self.model_metadata:
                del self.model_metadata[model_name]
            
            # Entferne die Registry-Einträge
            if model_name in self.model_registry:
                del self.model_registry[model_name]
                self.save_model_registry()
            
            logger.info(f"Modell '{model_name}' aus der Registry entfernt.")
        else:
            logger.warning(f"Modell '{model_name}' nicht in der Registry gefunden.")
    
    def list_models(self) -> List[str]:
        """
        Listet alle registrierten Modelle auf.
        
        Returns:
            List[str]: Liste der Modellnamen
        """
        return list(self.models.keys())
    
    def get_model_status(self, model_name: str) -> Dict[str, Any]:
        """
        Gibt den Status eines Modells zurück.
        
        Args:
            model_name: Der Name des Modells
            
        Returns:
            Dict[str, Any]: Der Status des Modells
        """
        if model_name in self.model_metadata:
            return {
                "name": model_name,
                "status": "active" if model_name in self.models else "inactive",
                "usage_count": self.model_metadata[model_name]["usage_count"],
                "success_rate": self.model_metadata[model_name]["success_rate"],
                "resource_usage": self.model_metadata[model_name]["resource_usage"],
                "version": self.model_metadata[model_name]["version"],
                "description": self.model_metadata[model_name]["description"]
            }
        else:
            logger.warning(f"Metadaten für Modell '{model_name}' nicht gefunden.")
            return {
                "name": model_name,
                "status": "unknown",
                "usage_count": 0,
                "success_rate": 0.0,
                "resource_usage": {
                    "cpu": 0.0,
                    "memory": 0.0,
                    "gpu": 0.0
                },
                "version": "unknown",
                "description": f"Modell {model_name}"
            }
    
    def get_model_config(self, model_name: str) -> Dict[str, Any]:
        """
        Gibt die Konfiguration eines Modells zurück.
        
        Args:
            model_name: Der Name des Modells
            
        Returns:
            Dict[str, Any]: Die Konfiguration des Modells
        """
        if model_name in self.models:
            try:
                # Hole die Konfiguration aus dem Modell
                config = self.models[model_name]["model"].config.to_dict()
                return config
            except Exception as e:
                logger.error(f"Fehler beim Abrufen der Konfiguration für Modell '{model_name}': {str(e)}", exc_info=True)
                return {}
        else:
            logger.warning(f"Modell '{model_name}' nicht gefunden.")
            return {}
    
    def get_model_metadata(self, model_name: str) -> Dict[str, Any]:
        """
        Gibt die Metadaten eines Modells zurück.
        
        Args:
            model_name: Der Name des Modells
            
        Returns:
            Dict[str, Any]: Die Metadaten des Modells
        """
        if model_name in self.model_metadata:
            return self.model_metadata[model_name]
        else:
            logger.warning(f"Metadaten für Modell '{model_name}' nicht gefunden.")
            return {}
    
    def update_model_metadata(self, model_name: str, updates: Dict[str, Any]):
        """
        Aktualisiert die Metadaten eines Modells.
        
        Args:
            model_name: Der Name des Modells
            updates: Die zu aktualisierenden Metadaten
        """
        if model_name in self.model_metadata:
            # Aktualisiere die Metadaten
            for key, value in updates.items():
                self.model_metadata[model_name][key] = value
            
            # Aktualisiere die Registry
            if model_name in self.model_registry:
                for key, value in updates.items():
                    if key in self.model_registry[model_name]:
                        self.model_registry[model_name][key] = value
                self.save_model_registry()
            
            logger.info(f"Metadaten für Modell '{model_name}' aktualisiert.")
        else:
            logger.warning(f"Metadaten für Modell '{model_name}' nicht gefunden.")
    
    def monitor_model_directory(self, interval: int = 60):
        """
        Überwacht das Modellverzeichnis auf Änderungen.
        
        Args:
            interval: Überwachungsintervall in Sekunden
        """
        if self.monitoring:
            logger.warning("Modellverzeichnis-Überwachung bereits aktiv.")
            return
        
        self.monitoring = True
        logger.info(f"Starte Modellverzeichnis-Überwachung (Intervall: {interval} Sekunden)...")
        
        def check_changes():
            last_modified = {}
            
            while self.monitoring:
                try:
                    # Prüfe alle registrierten Modelle
                    for model_name in list(self.models.keys()):
                        model_path = os.path.join(self.models_dir, model_name)
                        
                        # Prüfe, ob das Modell-Verzeichnis existiert
                        if not os.path.exists(model_path):
                            logger.warning(f"Modell-Verzeichnis '{model_path}' nicht gefunden. Entferne Modell '{model_name}' aus der Registry.")
                            self.unregister_model(model_name)
                            continue
                        
                        # Prüfe, ob sich das Modell geändert hat
                        current_mtime = os.path.getmtime(model_path)
                        if model_name not in last_modified:
                            last_modified[model_name] = current_mtime
                        elif current_mtime != last_modified[model_name]:
                            logger.info(f"Modell '{model_name}' wurde geändert. Lade neu...")
                            try:
                                # Entferne das alte Modell
                                self.unregister_model(model_name)
                                
                                # Lade das neue Modell
                                self.load_models()
                                
                                # Aktualisiere den letzten Änderungszeitpunkt
                                last_modified[model_name] = os.path.getmtime(model_path)
                                
                                logger.info(f"Modell '{model_name}' erfolgreich neu geladen.")
                            except Exception as e:
                                logger.error(f"Fehler beim Neuladen von Modell '{model_name}': {str(e)}", exc_info=True)
                
                except Exception as e:
                    logger.error(f"Fehler bei der Modellverzeichnis-Überwachung: {str(e)}", exc_info=True)
                
                # Warte vor der nächsten Überprüfung
                time.sleep(interval)
        
        # Starte den Überwachungs-Thread
        self.monitor_thread = threading.Thread(target=check_changes, daemon=True)
        self.monitor_thread.start()
    
    def stop_model_monitoring(self):
        """Stoppt die Modellverzeichnis-Überwachung."""
        if self.monitoring:
            self.monitoring = False
            logger.info("Modellverzeichnis-Überwachung gestoppt.")
        else:
            logger.warning("Modellverzeichnis-Überwachung war nicht aktiv.")